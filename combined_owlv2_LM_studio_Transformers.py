from PIL import ImageGrab, Image
from pathlib import Path
import matplotlib.pyplot as plt
import numpy as np
import time
import sys
import json
from typing import List, Dict, Tuple, Optional
import re

class DesktopObjectDetector:
     def __init__(self, project_root: Optional[Path] = None):
          """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è"""
          self.PROJECT_ROOT = project_root or Path(__file__).parent
          #print(f"PATH = {self.PROJECT_ROOT}")
        
          # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
          self.IMAGE_SAVE_DIR = self.PROJECT_ROOT / 'image_save'
          self.OUTPUT_DIR_OWLV2 = self.PROJECT_ROOT / 'Output_OWLv2'
          self.IMAGE_SAVE_DIR.mkdir(exist_ok=True)
          self.OUTPUT_DIR_OWLV2.mkdir(exist_ok=True)
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏
          self.text_queries = [
          ["desktop icon", "application icon", "shortcut icon"],
          ["window", "application window", "browser window"],
          #["taskbar", "start menu", "system tray"],
          #["button", "close button", "minimize button", "maximize button"],
          #["menu bar", "title bar", "status bar", "scroll bar"],
          #["file explorer", "folder icon", "document icon"],
          #["notification area", "search bar", "address bar"]
          ["blue icon", "green icon", "red icon", "yellow icon"],                     #–¥–æ–ø –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è
          #["small square icon", "large rectangular window", "thin horizontal bar"],   #–¥–æ–ø
          ["everything visible", "all UI elements", "all clickable items"],           #–¥–æ–ø
          #["text label", "title bar text", "menu text"]                               #–¥–æ–ø
        ]
        
          # –ü—É—Ç–∏ –∫ –º–æ–¥–µ–ª—è–º
          self.OWLv2_MODEL_PATH = self.PROJECT_ROOT / 'owlv2_large_patch14_ensemble'
          self.Qwen3_VL_MODEL_PATH = self.PROJECT_ROOT / 'Transformers_Qwen3_VL_4B_Instruct'
    
     def capture_screenshot(self) -> Path:
          screenshot = ImageGrab.grab()
          image_path = self.IMAGE_SAVE_DIR / 'new1.png'
          screenshot.save(image_path)
          print(f"‚úÖ –°–∫—Ä–∏–Ω—à–æ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {image_path}")
          return image_path
    
     def split_into_two_squares(self, image_path: Path) -> Tuple[Path, Path]:
          """–†–∞–∑–±–∏–≤–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è 1920x1080 –Ω–∞ –¥–≤–∞ –∫–≤–∞–¥—Ä–∞—Ç–∞ 1080x1080"""
          image = Image.open(image_path)
          image_1, image_2 = image.copy(), image.copy()
          
          left_cropped = image_1.crop((0, 0, 1080, 1080))
          right_cropped = image_2.crop((1920-1080, 0, 1920, 1080))
          
          left_image_path = self.IMAGE_SAVE_DIR / 'left_cropped.png'
          right_image_path = self.IMAGE_SAVE_DIR / 'right_cropped.png'
          
          left_cropped.save(left_image_path)
          right_cropped.save(right_image_path)
          
          #print("–õ–µ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ –ü—Ä–∞–≤–æ–µ:\n" {left_image_path},"\n" {right_image_path}")
          return left_image_path, right_image_path
    
     def process_with_owlv2(self, image_paths: List[Path], start_id = 1) -> List[Dict]:
          """–û–±—Ä–∞–±–∞—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ OWLv2"""
          from owlv2_large_patch14_ensemble.owlv2_5_5 import main_owl
          
          results = []
          current_id = start_id
          
          for image_path in image_paths:            
               result = main_owl(
                    model_path=self.OWLv2_MODEL_PATH,
                    image_path=image_path,
                    text_queries=self.text_queries,
                    output_path=self.OUTPUT_DIR_OWLV2,
                    start_id=current_id,
               )
               results.append(result)

               current_id += result['detection_count']
               #print(f"–ù–∞–π–¥–µ–Ω—ã –æ–±—ä–µ–∫—Ç—ã: {result['detection_count']}, —Å–ª–µ–¥—É—é—â–∏–π ID: {current_id}")
          
          return results
    
     def split_owl_results_into_parts(self, owl_results: List[Dict]) -> List[Image.Image]:
          """–†–∞–∑–±–∏–≤–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã OWLv2 –Ω–∞ 8 —á–∞—Å—Ç–µ–π —Å –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ–º"""        
          all_parts = []
          overlap = 54
          
          for result in owl_results:
               img = Image.open(result['visualization_path'])
               # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ 4 —á–∞—Å—Ç–∏ –±–µ–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
               parts = [
                    img.crop((0, 0, 540 + overlap, 540 + overlap)),        # –ª–µ–≤—ã–π –≤–µ—Ä—Ö
                    img.crop((540 - overlap, 0, 1080, 540 + overlap)),     # –ø—Ä–∞–≤—ã–π –≤–µ—Ä—Ö
                    img.crop((0, 540 - overlap, 540 + overlap, 1080)),     # –ª–µ–≤—ã–π –Ω–∏–∑
                    img.crop((540 - overlap, 540 - overlap, 1080, 1080))   # –ø—Ä–∞–≤—ã–π –Ω–∏–∑
               ]
               all_parts.extend(parts)

          #print(f"–í—Å–µ–≥–æ –ø–æ–ª—É—á–µ–Ω–æ —á–∞—Å—Ç–µ–π: {len(all_parts)}")
          return all_parts
    
     def show_all_parts_with_names(self, image_parts: List[Image.Image], title: str = "–í—Å–µ —á–∞—Å—Ç–∏ —Å –∏–º–µ–Ω–∞–º–∏"):
          """–í—ã–≤–æ–¥ 8 —á–∞—Å—Ç–µ–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ matplotlib"""
          
          image_parts_with_names = [(f"part_{i+1}", img) for i, img in enumerate(image_parts)]
          
          fig, axes = plt.subplots(2, 4, figsize=(16, 8))
          fig.suptitle(title, fontsize=16)
          
          for i, (name, img) in enumerate(image_parts_with_names):
               row = i // 4
               col = i % 4
               axes[row, col].imshow(img)
               axes[row, col].set_title(f"{name}\n{img.size}")
               axes[row, col].axis('off')
          
          plt.tight_layout()
          plt.show()
    
     def analyze_with_transformers(self, image_parts: List[Image.Image], query_text: str) -> Dict:
          """–ê–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ Qwen 3 VL Transformers (CPU)"""
          from Transformers_Qwen3_VL_4B_Instruct.Qwen_4_2 import main_qwen3
          
          qwen3_result = main_qwen3(
               model_path=self.Qwen3_VL_MODEL_PATH,
               image_path=image_parts,
               text_input=query_text,
          )

          return {
               "method": "transformers",
               "output_text": qwen3_result["output_qwen3_text"],
               "processing_time": qwen3_result["generation_time"],
               "raw_result": qwen3_result
          }
    
     def analyze_with_lm_studio(self, image_parts: List[Image.Image], query_text: str) -> Dict:
          """–ê–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ Qwen 3 VL LM Studio API (GPU)"""          
          from API_LM_studio.Localhost_LM_studio_PIL_image import LMStudioVLM
          vlm = LMStudioVLM()
               
          vlm_result_all = vlm.describe_multiple_images(
                    image_inputs=image_parts,
                    prompt=query_text,
          )
          
          # c—Ä–∞–±–æ—Ç–∞–µ—Ç –µ—Å–ª–∏ success == True
          if vlm_result_all.get("success"):
               return {
                    "method": "lm_studio",
                    "output_text": vlm_result_all["output_text"],
                    "processing_time": vlm_result_all["processing_time"],
                    "raw_result": vlm_result_all
               }
          else: 
               return {
                    "error": vlm_result_all.get("error", "–û—à–∏–±–∫–∞ API")
               }

    
     def extract_object_positions(self, analysis_text: str) -> Dict[int, int]:
          """–ò–∑–≤–ª–µ–∫–∞–µ—Ç id bbox –æ–±—ä–µ–∫—Ç–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞"""
          #–≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ –æ–¥–Ω–æ–º—É (1) ID –Ω–∞ –ø–æ–∑–∏—Ü–∏—é (—Ñ–æ—Ä–º–∞—Ç 1: 12, 2: 7)
          positions = {}

          # –£–±–∏—Ä–∞–µ—Ç –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ —Ä–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ —Å—Ç—Ä–æ–∫–∏
          lines = analysis_text.strip().split('\n')
          
          for line in lines:
               line = line.strip()
               # –ü—Ä–æ–ø—É—Å–∫ –ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫
               if not line:
                    continue
               # –ø–æ–∏—Å–∫ —Å—Ç—Ä–æ–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –≤—ã–≥–ª—è–¥—è—Ç –∫–∞–∫ "X: Y" –≥–¥–µ X - –Ω–æ–º–µ—Ä, Y - —á–∏—Å–ª–æ –∏–ª–∏ —Å–ø–∏—Å–æ–∫
               if ':' in line:
                    try:
                         # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –Ω–æ–º–µ—Ä –≤–æ–ø—Ä–æ—Å–∞ –∏ –∑–Ω–∞—á–µ–Ω–∏–µ
                         question_part, value_part = line.split(':', 1)
                         
                         # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–æ–º–µ—Ä –≤–æ–ø—Ä–æ—Å–∞ (–±–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ —Ü–∏—Ñ—Ä—ã)
                         question_match = re.search(r'\d+', question_part)
                         if not question_match:
                              continue
                              
                         question_num = int(question_match.group())
                         
                         # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ ID –æ–±—ä–µ–∫—Ç–∞ - –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ —Ñ–æ—Ä–º–∞—Ç–∞
                         # –§–æ—Ä–º–∞—Ç—ã: "1: 123", "1: [123]", "1: [123, 456]", "ID 1: 123"
                         
                         # –£–±–∏—Ä–∞–µ–º –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã–µ —Å–∫–æ–±–∫–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
                         value_part = value_part.replace('[', '').replace(']', '').strip()
                         
                         # –ò—â–µ–º –ø–µ—Ä–≤–æ–µ —á–∏—Å–ª–æ –≤ –∑–Ω–∞—á–µ–Ω–∏–∏
                         value_match = re.search(r'\d+', value_part)
                         if value_match:
                              object_id = int(value_match.group())
                              #–ø—Ä—è–º–æ–µ –ø—Ä–∏—Å–≤–æ–µ–Ω–∏–µ —ç–ª–µ–º–µ–Ω—Ç–∞ –∫ —Å–ª–æ–≤–∞—Ä—é
                              positions[question_num] = object_id
                              print(f"‚úÖ –í–æ–ø—Ä–æ—Å {question_num}: –æ–±—ä–µ–∫—Ç ID {object_id}")
                              #print("positions —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã",positions)
                         else:
                              print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å ID –∏–∑ —Å—Ç—Ä–æ–∫–∏: {line}")
                              
                    except (ValueError, IndexError, AttributeError) as e:
                         print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç—Ä–æ–∫–∏ '{line}': {e}")
                         continue
          
          return positions
     
     def print_final_results(self, results: Dict):
        """–í—ã–≤–æ–¥–∏—Ç –∏—Ç–æ–≥–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã"""
        print("\n" + "=" * 60)
        print("üéØ –ò–¢–û–ì–û–í–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´")
        print("=" * 60)
          
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∞–Ω–∞–ª–∏–∑–µ
        analysis = results["vlm_result_all"]
        print(f"üîß –ú–µ—Ç–æ–¥ –∞–Ω–∞–ª–∏–∑–∞: {results['analysis_method']}")
        print(f"‚è±Ô∏è –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {analysis['processing_time']:.2f} —Å–µ–∫")
          
        print(f"\nüìù –û—Ç–≤–µ—Ç VLM:\n{analysis['output_text']}")
               
        # –ü–æ–∑–∏—Ü–∏–∏ –æ–±—ä–µ–∫—Ç–æ–≤
        positions = results["object_positions"]
        input_items = results["input_items"]
        if positions:
            print("\nüìç –ù–∞–π–¥–µ–Ω–Ω—ã–µ –ø–æ–∑–∏—Ü–∏–∏:")
            for question_num in sorted(positions.keys()):
                object_id = positions[question_num]
                obj_name = f"–û–±—ä–µ–∫—Ç {question_num}"
                if question_num - 1 < len(input_items):
                     obj_name = input_items[question_num - 1]
                
                print(f"  {obj_name} (–≤–æ–ø—Ä–æ—Å {question_num}): ID {object_id}")
        else:
            print("\n‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø–æ–∑–∏—Ü–∏–∏ –æ–±—ä–µ–∫—Ç–æ–≤")
          
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–µ—Ç–µ–∫—Ü–∏—è—Ö
        total_detections = sum(result['detection_count'] for result in results["owl_results"])
        print(f"\nüìä –í—Å–µ–≥–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ –æ–±—ä–µ–∫—Ç–æ–≤: {total_detections}")
    
    
     def get_detection_by_id(self, owl_results: List[Dict], object_id: int) -> Optional[Dict]:
          """–ù–∞—Ö–æ–¥–∏—Ç –¥–µ—Ç–µ–∫—Ü–∏—é –ø–æ ID –≤–æ –≤—Å–µ—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö OWLv2"""
          for result in owl_results:
               with open(result['json_path'], 'r') as f:
                    data = json.load(f)
               
               for detection in data['detections']:
                    if detection['id'] == object_id:
                         return detection
          return None
    
     def get_coordinates_for_click(self, detection: Dict) -> Tuple[float, float]:
          """–ü–æ–ª—É—á–∞–µ—Ç –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –¥–ª—è –∫–ª–∏–∫–∞ –∏–∑ –¥–µ—Ç–µ–∫—Ü–∏–∏"""
          coords = detection['coordinates']
          center_x = (coords['x1'] + coords['x2']) / 2
          center_y = (coords['y1'] + coords['y2']) / 2
          return center_x, center_y
    

      #------------------------#
     ### –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª —Ä–∞–±–æ—Ç—ã ##
      #-----------------------#
     def run_full_pipeline(self, analysis_method: str = "transformers", 
                           show_math_plot_fig = "show",
                           show_final_results="show",
                           input_items=None) -> Dict:
          if input_items is None:
               input_items = ["Trash can/recycle bin", "Web browser"]
     
          """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
          print("=" * 60)
          print("Start")
          print("=" * 60)
          
          # 1. –ó–∞—Ö–≤–∞—Ç —Å–∫—Ä–∏–Ω—à–æ—Ç–∞
          screenshot_path = self.capture_screenshot()
          
          # 2. –†–∞–∑–±–∏–≤–∫–∞ –Ω–∞ –¥–≤–∞ –∫–≤–∞–¥—Ä–∞—Ç–∞
          left_path, right_path = self.split_into_two_squares(screenshot_path)
          
          # 3. OWLv2 –¥–µ—Ç–µ–∫—Ü–∏—è
          owl_results = self.process_with_owlv2([left_path, right_path])
          
          # 4. –†–∞–∑–±–∏–≤–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–∞ —á–∞—Å—Ç–∏
          image_parts = self.split_owl_results_into_parts(owl_results)
          
          # 5. –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —á–∞—Å—Ç–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
          if show_math_plot_fig == "show":
               self.show_all_parts_with_names(image_parts, "–ß–∞—Å—Ç–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ Qwen 3 VL")
          
          # 6. –¢–µ–∫—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
          # –§–æ—Ä–º–∏—Ä—É–µ–º —à–∞–±–ª–æ–Ω –æ—Ç–≤–µ—Ç–∞
          questions = "\n".join([
          f"{i+1}. {item.replace('_', ' ')} - which NUMBER?" 
          for i, item in enumerate(input_items)
          ])

          result_template = "\n".join([
          f"{i+1}: [number]" 
          for i in range(len(input_items))
          ])

          query_text = f'''There are photos in front of you - screenshots with numbered elements.
            Answer these questions about the numbered objects:

            {questions}

            ANSWER FORMAT:
            Answer preparation: [Concise analysis of object positions and numbers]
            Final result:
            {result_template}'''

          print(query_text)
        
          # 7. –≤—ã–±–æ—Ä –º–µ—Ç–æ–¥–∞ –∞–Ω–∞–ª–∏–∑–∞ –∏ –ø–µ—Ä–µ–¥–∞—á–∞ —á–∞—Å—Ç–µ–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è + –∑–∞–ø—Ä–æ—Å–∞ —Ç–µ–∫—Å—Ç–æ–º
          if analysis_method == "transformers":
               vlm_result_all = self.analyze_with_transformers(image_parts, query_text)
               """return{
                    "method": "transformers",
                    "output_text": qwen3_result["output_qwen3_text"],
                    "processing_time": qwen3_result["generation_time"],
                    "raw_result": qwen3_result}"""
               
          elif analysis_method == "lm_studio":
               vlm_result_all = self.analyze_with_lm_studio(image_parts, query_text)
               """return{
                    "method": "lm_studio",
                    "output_text": vlm_result_all["output_text"],
                    "processing_time": vlm_result_all["processing_time"],
                    "raw_result": vlm_result_all}"""
          
          else:
               raise ValueError("–ù–µ–≤–µ—Ä–Ω—ã–π –º–µ—Ç–æ–¥ –∞–Ω–∞–ª–∏–∑–∞. –í—ã–±–µ—Ä–∏—Ç–µ 'transformers' –∏–ª–∏ 'lm_studio'")
          
          # 8. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ id bbox –æ–±—ä–µ–∫—Ç–æ–≤
          object_id = {}
          object_id = self.extract_object_positions(vlm_result_all["output_text"])
          
          # 9. –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
          final_result = {
               "screenshot_path": screenshot_path,
               "split_images": [left_path, right_path],
               "owl_results": owl_results,
               "image_parts": image_parts,        

               "vlm_result_all": vlm_result_all, # –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –ø–æ—Å–ª–µ analyze_with (7 –ø—É–Ω–∫—Ç)
               "object_positions": object_id, # —Å–ª–æ–≤–∞—Ä—å c id –∏ –Ω–æ–º–µ—Ä–æ–º –∑–∞–ø—Ä–æ—Å–∞ {1: 12, 2: 7}
               "analysis_method": analysis_method, #transformers –∏–ª–∏ lm_studio
               "input_items": input_items, #–≤—Ö–æ–¥–Ω–æ–π –Ω–∞–±–æ—Ä –æ–±—ä–µ–∫—Ç–æ–≤
               "VLM_output_text": vlm_result_all['output_text'], #—Ç–µ–∫—Å—Ç–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ VLM
               "VLM_processing_time": vlm_result_all['processing_time'], # –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ VLM
                              # —á—Ç–æ –≤—ã—Ö–æ–¥–∏—Ç –∏–∑ vlm_result_all
                              #     vlm_result_all = return{
                              #          "method": "lm_studio",
                              #          "output_text": vlm_result_all["output_text"],
                              #          "processing_time": vlm_result_all["processing_time"],
                              #          "raw_result": vlm_result_all}
          }

          # 10. –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
          if show_final_results == "show":
               self.print_final_results(final_result)
          
          return final_result


# –¥–ª—è –∑–∞–ø—É—Å–∫–∞ —Ñ–∞–π–ª–∞, –±–µ–∑ main.py
if __name__ == "__main__":
      # 1. –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä –∫–ª–∞—Å—Å–∞
     detector = DesktopObjectDetector()

     #detector.run_full_pipeline("transformers")
     detector.run_full_pipeline("lm_studio",
                                show_math_plot_fig = "hide",
                                show_final_results = "show")
